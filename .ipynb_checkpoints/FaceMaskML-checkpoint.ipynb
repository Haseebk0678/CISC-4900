{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.3 in ./lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: numpy==1.24.2 in ./lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.24.2)\n",
      "Requirement already satisfied: pytz==2022.7.1 in ./lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2022.7.1)\n",
      "Requirement already satisfied: setuptools==67.4.0 in ./lib/python3.9/site-packages (from -r requirements.txt (line 4)) (67.4.0)\n",
      "Requirement already satisfied: pip==23.0.1 in ./lib/python3.9/site-packages (from -r requirements.txt (line 5)) (23.0.1)\n",
      "Requirement already satisfied: jinja2==3.1.2 in ./lib/python3.9/site-packages (from -r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: IPython==8.10.0 in ./lib/python3.9/site-packages (from -r requirements.txt (line 7)) (8.10.0)\n",
      "Requirement already satisfied: matplotlib==3.7.0 in ./lib/python3.9/site-packages (from -r requirements.txt (line 8)) (3.7.0)\n",
      "Collecting tensorflow-cpu==2.11.0\n",
      "  Downloading tensorflow_cpu-2.11.0-cp39-cp39-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy==1.10.1 in ./lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./lib/python3.9/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.9/site-packages (from jinja2==3.1.2->-r requirements.txt (line 6)) (2.1.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (3.0.36)\n",
      "Requirement already satisfied: decorator in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: stack-data in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (0.6.2)\n",
      "Requirement already satisfied: pickleshare in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (5.9.0)\n",
      "Requirement already satisfied: matplotlib-inline in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (2.14.0)\n",
      "Requirement already satisfied: appnope in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (0.1.3)\n",
      "Requirement already satisfied: backcall in ./lib/python3.9/site-packages (from IPython==8.10.0->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (9.4.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./lib/python3.9/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 8)) (1.0.7)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (15.0.6.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (4.5.0)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.30.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.51.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./lib/python3.9/site-packages (from tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (3.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.38.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.0->-r requirements.txt (line 8)) (3.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./lib/python3.9/site-packages (from jedi>=0.16->IPython==8.10.0->-r requirements.txt (line 7)) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./lib/python3.9/site-packages (from pexpect>4.3->IPython==8.10.0->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->IPython==8.10.0->-r requirements.txt (line 7)) (0.2.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (2.28.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (2.16.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (3.4.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pure-eval in ./lib/python3.9/site-packages (from stack-data->IPython==8.10.0->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./lib/python3.9/site-packages (from stack-data->IPython==8.10.0->-r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./lib/python3.9/site-packages (from stack-data->IPython==8.10.0->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-cpu==2.11.0->-r requirements.txt (line 9)) (3.2.2)\n",
      "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow-cpu\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.9.0\n",
      "    Uninstalling tensorflow-estimator-2.9.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.9.0\n",
      "    Uninstalling keras-2.9.0:\n",
      "      Successfully uninstalled keras-2.9.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.9.1\n",
      "    Uninstalling tensorboard-2.9.1:\n",
      "      Successfully uninstalled tensorboard-2.9.1\n",
      "Successfully installed flatbuffers-23.3.3 keras-2.11.0 tensorboard-2.11.2 tensorflow-cpu-2.11.0 tensorflow-estimator-2.11.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scipy 1.10.1\n",
      "Uninstalling scipy-1.10.1:\n",
      "  Successfully uninstalled scipy-1.10.1\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.10.1-cp39-cp39-macosx_10_9_x86_64.whl (35.2 MB)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in ./lib/python3.9/site-packages (from scipy) (1.24.2)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall -y scipy\n",
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "\n",
    "\n",
    "test_mask = [] \n",
    "test_no_mask = []\n",
    "# I would do this in a fancy os.loop way but I was using google colab and didn't really want to mess with the function too much\n",
    "train_data_mask_dir=\"New_Masks_Dataset/Train/Mask\"\n",
    "train_data_no_mask_dir=\"New_Masks_Dataset/Train/Non_Mask\"\n",
    "test_data_mask_dir=\"New_Masks_Dataset/Test/Mask\"\n",
    "test_data_no_mask_dir=\"New_Masks_Dataset/Test/Non_Mask\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_imagePaths_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "# https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import os\n",
    "\n",
    "IMAGE_HEIGHT  = 100\n",
    "IMAGE_WIDTH = 100\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "\n",
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        # cv2_imshow(img)\n",
    "        # Has to be like this because of Python Ambiguity\n",
    "        if img is not None:\n",
    "            grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(grayscale, input_shape)\n",
    "            resized = np.reshape(resized, input_shape[0] * input_shape[1])\n",
    "            images.append(resized)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = load_images_from_folder(train_data_mask_dir)\n",
    "train_no_mask = load_images_from_folder(train_data_no_mask_dir)\n",
    "test_mask = load_images_from_folder(test_data_mask_dir)\n",
    "test_no_mask = (load_images_from_folder(test_data_no_mask_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {'No_Mask': 0, 'Mask': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mask = [1] * len(train_mask)\n",
    "y_train_no_mask = [0] * len(train_no_mask)\n",
    "y_test_mask = [1] * len(test_mask)\n",
    "y_test_no_mask = [0] * len(test_no_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'label': y_train_mask,'mask_data': train_mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/4ybwj4pj54x1sz2qhfgy1b9m0000gn/T/ipykernel_80595/1233198709.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_train = df_train.append(pd.DataFrame({'label': y_train_no_mask, 'mask_data': train_no_mask}), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.append(pd.DataFrame({'label': y_train_no_mask, 'mask_data': train_no_mask}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mask_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0</td>\n",
       "      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>[47, 37, 24, 46, 89, 148, 159, 119, 145, 182, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>[255, 255, 255, 255, 255, 254, 251, 173, 170, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>[129, 133, 131, 135, 136, 139, 134, 141, 133, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>[219, 219, 219, 219, 219, 218, 218, 218, 219, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "      <td>[225, 227, 225, 224, 223, 223, 223, 223, 225, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>[136, 143, 146, 153, 231, 229, 253, 255, 254, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1</td>\n",
       "      <td>[192, 228, 235, 231, 220, 174, 187, 222, 169, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0</td>\n",
       "      <td>[255, 255, 255, 255, 255, 255, 254, 246, 229, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>[253, 253, 253, 253, 253, 253, 253, 253, 253, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                          mask_data\n",
       "585      0  [255, 255, 255, 255, 255, 255, 255, 255, 255, ...\n",
       "19       1  [47, 37, 24, 46, 89, 148, 159, 119, 145, 182, ...\n",
       "372      0  [255, 255, 255, 255, 255, 254, 251, 173, 170, ...\n",
       "104      1  [129, 133, 131, 135, 136, 139, 134, 141, 133, ...\n",
       "303      0  [219, 219, 219, 219, 219, 218, 218, 218, 219, ...\n",
       "..     ...                                                ...\n",
       "285      1  [225, 227, 225, 224, 223, 223, 223, 223, 225, ...\n",
       "395      0  [136, 143, 146, 153, 231, 229, 253, 255, 254, ...\n",
       "227      1  [192, 228, 235, 231, 220, 174, 187, 222, 169, ...\n",
       "406      0  [255, 255, 255, 255, 255, 255, 254, 246, 229, ...\n",
       "243      1  [253, 253, 253, 253, 253, 253, 253, 253, 253, ...\n",
       "\n",
       "[599 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sample(frac = 1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 1:] / 255.0\n",
    "X_train = pd.DataFrame(X_train['mask_data'].tolist())\n",
    "y_train = df_train.iloc[:, :1]\n",
    "\n",
    "# .astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/4ybwj4pj54x1sz2qhfgy1b9m0000gn/T/ipykernel_80595/4284791088.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test = df_test.append(pd.DataFrame({'label': y_test_no_mask, 'mask_data': test_no_mask}), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mask_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>[29, 33, 32, 29, 29, 29, 29, 28, 28, 32, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>[53, 112, 137, 130, 63, 67, 71, 58, 26, 31, 52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>[205, 194, 196, 190, 182, 164, 137, 125, 151, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>[207, 190, 180, 187, 179, 170, 59, 47, 186, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>[47, 48, 48, 48, 48, 49, 50, 49, 50, 50, 50, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>[179, 178, 177, 177, 177, 176, 177, 177, 176, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>[209, 210, 214, 215, 215, 213, 210, 210, 213, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>[236, 236, 236, 236, 236, 236, 236, 236, 236, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>[243, 244, 244, 244, 243, 243, 243, 241, 241, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 3, 3, 4, 6, 8, 8, 7, 6, 6, 5, 3, 3, 8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                          mask_data\n",
       "20      1  [29, 33, 32, 29, 29, 29, 29, 28, 28, 32, 27, 2...\n",
       "81      0  [53, 112, 137, 130, 63, 67, 71, 58, 26, 31, 52...\n",
       "42      1  [205, 194, 196, 190, 182, 164, 137, 125, 151, ...\n",
       "88      0  [207, 190, 180, 187, 179, 170, 59, 47, 186, 18...\n",
       "76      0  [47, 48, 48, 48, 48, 49, 50, 49, 50, 50, 50, 5...\n",
       "..    ...                                                ...\n",
       "55      0  [179, 178, 177, 177, 177, 176, 177, 177, 176, ...\n",
       "52      0  [209, 210, 214, 215, 215, 213, 210, 210, 213, ...\n",
       "56      0  [236, 236, 236, 236, 236, 236, 236, 236, 236, ...\n",
       "31      1  [243, 244, 244, 244, 243, 243, 243, 241, 241, ...\n",
       "34      1  [3, 1, 3, 3, 4, 6, 8, 8, 7, 6, 6, 5, 3, 3, 8, ...\n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame({'label': y_test_mask,'mask_data': test_mask})\n",
    "df_test = df_test.append(pd.DataFrame({'label': y_test_no_mask, 'mask_data': test_no_mask}), ignore_index=True)\n",
    "\n",
    "df_test = df_test.sample(frac = 1)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[:, 1:] / 255.0\n",
    "X_test = pd.DataFrame(X_test['mask_data'].tolist())\n",
    "y_test = df_test.iloc[:, :1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.values.reshape(-1,100,100)\n",
    "x_test = X_test.values.reshape(-1,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "# input image dimensions\n",
    "input_shape = (100, 100, 1)\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599, 100, 100)\n",
      "(99, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 09:31:22.117131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 98, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 33856)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 33856)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 67714     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,530\n",
      "Trainable params: 86,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The parameters I chose here were also from a project I did earlier, I'll link it here\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.8315 - accuracy: 0.4992 - val_loss: 0.7153 - val_accuracy: 0.4949\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6873 - accuracy: 0.5476 - val_loss: 0.6267 - val_accuracy: 0.7980\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 12s 3s/step - loss: 0.5540 - accuracy: 0.8147 - val_loss: 0.5668 - val_accuracy: 0.7475\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4492 - accuracy: 0.8030 - val_loss: 0.4932 - val_accuracy: 0.8081\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 8s 1s/step - loss: 0.3922 - accuracy: 0.8164 - val_loss: 0.4405 - val_accuracy: 0.8182\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3716 - accuracy: 0.8264 - val_loss: 0.4285 - val_accuracy: 0.8384\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3533 - accuracy: 0.8414 - val_loss: 0.4164 - val_accuracy: 0.8283\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3254 - accuracy: 0.8631 - val_loss: 0.3951 - val_accuracy: 0.8081\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.3088 - accuracy: 0.8698 - val_loss: 0.4067 - val_accuracy: 0.8384\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2959 - accuracy: 0.8581 - val_loss: 0.3926 - val_accuracy: 0.8283\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2753 - accuracy: 0.8865 - val_loss: 0.3733 - val_accuracy: 0.8081\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2788 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8081\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2535 - accuracy: 0.8982 - val_loss: 0.3921 - val_accuracy: 0.8384\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2409 - accuracy: 0.9149 - val_loss: 0.4095 - val_accuracy: 0.8182\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2373 - accuracy: 0.9065 - val_loss: 0.3932 - val_accuracy: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1e8c95ac0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3931739032268524\n",
      "Test accuracy: 0.7979797720909119\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask\n\u001b[1;32m      3\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mroute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhello_world\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    return \"<p>Hello, World!</p>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c13209e22e8d7786781c444ec5dd3ab2bdb4894b22799155f2d9a5b3d32d4296"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
