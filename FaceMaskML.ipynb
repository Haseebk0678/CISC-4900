{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\r\n",
      "anyio==3.6.2\r\n",
      "appnope==0.1.3\r\n",
      "argon2-cffi==21.3.0\r\n",
      "argon2-cffi-bindings==21.2.0\r\n",
      "arrow==1.2.3\r\n",
      "asttokens==2.2.1\r\n",
      "astunparse==1.6.3\r\n",
      "attrs==22.2.0\r\n",
      "backcall==0.2.0\r\n",
      "beautifulsoup4==4.11.2\r\n",
      "bleach==6.0.0\r\n",
      "cachetools==5.3.0\r\n",
      "certifi==2022.12.7\r\n",
      "cffi==1.15.1\r\n",
      "charset-normalizer==3.1.0\r\n",
      "click==8.1.3\r\n",
      "comm==0.1.2\r\n",
      "contourpy==1.0.7\r\n",
      "cycler==0.11.0\r\n",
      "debugpy==1.6.6\r\n",
      "decorator==5.1.1\r\n",
      "defusedxml==0.7.1\r\n",
      "executing==1.2.0\r\n",
      "fastjsonschema==2.16.3\r\n",
      "Flask==2.2.3\r\n",
      "flatbuffers==1.12\r\n",
      "fonttools==4.39.0\r\n",
      "fqdn==1.5.1\r\n",
      "gast==0.4.0\r\n",
      "google-auth==2.16.2\r\n",
      "google-auth-oauthlib==0.4.6\r\n",
      "google-pasta==0.2.0\r\n",
      "grpcio==1.51.3\r\n",
      "h5py==3.8.0\r\n",
      "idna==3.4\r\n",
      "importlib-metadata==6.0.0\r\n",
      "importlib-resources==5.12.0\r\n",
      "ipykernel==6.21.3\r\n",
      "ipython==8.10.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==8.0.4\r\n",
      "isoduration==20.11.0\r\n",
      "itsdangerous==2.1.2\r\n",
      "jedi==0.18.2\r\n",
      "Jinja2==3.1.2\r\n",
      "joblib==1.2.0\r\n",
      "jsonpointer==2.3\r\n",
      "jsonschema==4.17.3\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-console==6.6.3\r\n",
      "jupyter-events==0.6.3\r\n",
      "jupyter_client==8.0.3\r\n",
      "jupyter_core==5.2.0\r\n",
      "jupyter_server==2.4.0\r\n",
      "jupyter_server_terminals==0.4.4\r\n",
      "jupyterlab-pygments==0.2.2\r\n",
      "jupyterlab-widgets==3.0.5\r\n",
      "keras==2.9.0\r\n",
      "Keras-Preprocessing==1.1.2\r\n",
      "kiwisolver==1.4.4\r\n",
      "libclang==15.0.6.1\r\n",
      "Markdown==3.4.1\r\n",
      "MarkupSafe==2.1.2\r\n",
      "matplotlib==3.7.0\r\n",
      "matplotlib-inline==0.1.6\r\n",
      "mistune==2.0.5\r\n",
      "nbclassic==0.5.3\r\n",
      "nbclient==0.7.2\r\n",
      "nbconvert==7.2.10\r\n",
      "nbformat==5.7.3\r\n",
      "nest-asyncio==1.5.6\r\n",
      "notebook==6.5.3\r\n",
      "notebook_shim==0.2.2\r\n",
      "numpy==1.24.2\r\n",
      "oauthlib==3.2.2\r\n",
      "opencv-python==4.7.0.72\r\n",
      "opt-einsum==3.3.0\r\n",
      "packaging==23.0\r\n",
      "pandas==1.5.3\r\n",
      "pandocfilters==1.5.0\r\n",
      "parso==0.8.3\r\n",
      "pexpect==4.8.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==9.4.0\r\n",
      "pkgutil_resolve_name==1.3.10\r\n",
      "platformdirs==3.1.1\r\n",
      "prometheus-client==0.16.0\r\n",
      "prompt-toolkit==3.0.38\r\n",
      "protobuf==3.19.6\r\n",
      "psutil==5.9.4\r\n",
      "ptyprocess==0.7.0\r\n",
      "pure-eval==0.2.2\r\n",
      "pyasn1==0.4.8\r\n",
      "pyasn1-modules==0.2.8\r\n",
      "pycparser==2.21\r\n",
      "Pygments==2.14.0\r\n",
      "pyparsing==3.0.9\r\n",
      "pyrsistent==0.19.3\r\n",
      "python-dateutil==2.8.2\r\n",
      "python-json-logger==2.0.7\r\n",
      "pytz==2022.7.1\r\n",
      "PyYAML==6.0\r\n",
      "pyzmq==25.0.1\r\n",
      "qtconsole==5.4.1\r\n",
      "QtPy==2.3.0\r\n",
      "requests==2.28.2\r\n",
      "requests-oauthlib==1.3.1\r\n",
      "rfc3339-validator==0.1.4\r\n",
      "rfc3986-validator==0.1.1\r\n",
      "rsa==4.9\r\n",
      "scikit-learn==1.2.2\r\n",
      "scipy==1.10.1\r\n",
      "Send2Trash==1.8.0\r\n",
      "six==1.16.0\r\n",
      "sniffio==1.3.0\r\n",
      "soupsieve==2.4\r\n",
      "stack-data==0.6.2\r\n",
      "tensorboard==2.9.1\r\n",
      "tensorboard-data-server==0.6.1\r\n",
      "tensorboard-plugin-wit==1.8.1\r\n",
      "tensorflow==2.9.1\r\n",
      "tensorflow-estimator==2.9.0\r\n",
      "tensorflow-io-gcs-filesystem==0.31.0\r\n",
      "termcolor==2.2.0\r\n",
      "terminado==0.17.1\r\n",
      "threadpoolctl==3.1.0\r\n",
      "tinycss2==1.2.1\r\n",
      "tornado==6.2\r\n",
      "traitlets==5.9.0\r\n",
      "typing_extensions==4.5.0\r\n",
      "uri-template==1.2.0\r\n",
      "urllib3==1.26.15\r\n",
      "wcwidth==0.2.6\r\n",
      "webcolors==1.12\r\n",
      "webencodings==0.5.1\r\n",
      "websocket-client==1.5.1\r\n",
      "Werkzeug==2.2.3\r\n",
      "widgetsnbextension==4.0.5\r\n",
      "wrapt==1.15.0\r\n",
      "zipp==3.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "\n",
    "\n",
    "test_mask = [] \n",
    "test_no_mask = []\n",
    "# I would do this in a fancy os.loop way but I was using google colab and didn't really want to mess with the function too much\n",
    "train_data_mask_dir=\"New_Masks_Dataset/Train/Mask\"\n",
    "train_data_no_mask_dir=\"New_Masks_Dataset/Train/Non_Mask\"\n",
    "val_data_mask_dir = 'New_Masks_Dataset/Validation/Mask'\n",
    "val_data_no_mask_dir = 'New_Masks_Dataset/Validation/Non_Mask'\n",
    "test_data_mask_dir=\"New_Masks_Dataset/Test/Mask\"\n",
    "test_data_no_mask_dir=\"New_Masks_Dataset/Test/Non_Mask\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_imagePaths_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "# https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import os\n",
    "\n",
    "IMAGE_HEIGHT  = 100\n",
    "IMAGE_WIDTH = 100\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "\n",
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        # cv2_imshow(img)\n",
    "        # Has to be like this because of Python Ambiguity\n",
    "        if img is not None:\n",
    "            grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(grayscale, input_shape)\n",
    "            resized = np.reshape(resized, input_shape[0] * input_shape[1])\n",
    "            images.append(resized)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_mask = load_images_from_folder(train_data_mask_dir)\n",
    "train_no_mask = load_images_from_folder(train_data_no_mask_dir)\n",
    "# Val\n",
    "val_mask = load_images_from_folder(val_data_mask_dir)\n",
    "val_no_mask = load_images_from_folder(val_data_no_mask_dir)\n",
    "# Test\n",
    "test_mask = load_images_from_folder(test_data_mask_dir)\n",
    "test_no_mask = (load_images_from_folder(test_data_no_mask_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mask = [1] * len(train_mask)\n",
    "y_train_no_mask = [0] * len(train_no_mask)\n",
    "\n",
    "y_val_mask = [1] * len(val_mask)\n",
    "y_val_no_mask = [0] * len(val_no_mask)\n",
    "\n",
    "y_test_mask = [1] * len(test_mask)\n",
    "y_test_no_mask = [0] * len(test_no_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'label': y_train_mask,'mask_data': train_mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/4ybwj4pj54x1sz2qhfgy1b9m0000gn/T/ipykernel_35193/1233198709.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_train = df_train.append(pd.DataFrame({'label': y_train_no_mask, 'mask_data': train_no_mask}), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.append(pd.DataFrame({'label': y_train_no_mask, 'mask_data': train_no_mask}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mask_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0</td>\n",
       "      <td>[254, 255, 254, 254, 158, 174, 169, 160, 145, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1</td>\n",
       "      <td>[15, 15, 17, 18, 19, 18, 19, 19, 20, 19, 20, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>[24, 26, 27, 27, 28, 29, 29, 33, 32, 32, 31, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0</td>\n",
       "      <td>[255, 255, 255, 255, 255, 254, 253, 254, 253, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>[51, 83, 102, 107, 99, 78, 49, 58, 79, 80, 81,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>[124, 113, 127, 126, 126, 125, 124, 125, 125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>[255, 255, 255, 255, 255, 255, 254, 253, 252, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0</td>\n",
       "      <td>[254, 254, 231, 143, 145, 149, 149, 154, 151, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[103, 107, 108, 110, 106, 104, 103, 100, 96, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>[166, 153, 149, 144, 134, 129, 130, 133, 135, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                          mask_data\n",
       "542      0  [254, 255, 254, 254, 158, 174, 169, 160, 145, ...\n",
       "267      1  [15, 15, 17, 18, 19, 18, 19, 19, 20, 19, 20, 1...\n",
       "207      1  [24, 26, 27, 27, 28, 29, 29, 33, 32, 32, 31, 3...\n",
       "445      0  [255, 255, 255, 255, 255, 254, 253, 254, 253, ...\n",
       "312      0  [51, 83, 102, 107, 99, 78, 49, 58, 79, 80, 81,...\n",
       "..     ...                                                ...\n",
       "400      0  [124, 113, 127, 126, 126, 125, 124, 125, 125, ...\n",
       "416      0  [255, 255, 255, 255, 255, 255, 254, 253, 252, ...\n",
       "504      0  [254, 254, 231, 143, 145, 149, 149, 154, 151, ...\n",
       "4        1  [103, 107, 108, 110, 106, 104, 103, 100, 96, 1...\n",
       "187      1  [166, 153, 149, 144, 134, 129, 130, 133, 135, ...\n",
       "\n",
       "[599 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sample(frac = 1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 1:] / 255.0\n",
    "X_train = pd.DataFrame(X_train['mask_data'].tolist())\n",
    "y_train = df_train.iloc[:, :1]\n",
    "\n",
    "# .astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/4ybwj4pj54x1sz2qhfgy1b9m0000gn/T/ipykernel_35193/3146285510.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_val = df_val.append(pd.DataFrame({'label': y_val_no_mask, 'mask_data': val_no_mask}), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mask_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>[75, 85, 82, 85, 83, 85, 84, 86, 79, 82, 86, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>[111, 106, 107, 107, 110, 110, 105, 106, 103, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>[118, 132, 140, 152, 157, 165, 170, 172, 176, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>[170, 187, 169, 128, 127, 124, 123, 136, 137, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>[17, 16, 19, 15, 16, 19, 21, 18, 24, 25, 28, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>[194, 194, 195, 196, 196, 196, 198, 197, 196, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>[196, 205, 183, 186, 184, 139, 208, 205, 195, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>[189, 194, 200, 198, 196, 195, 190, 174, 170, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>[85, 52, 34, 30, 33, 32, 34, 69, 56, 68, 90, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>[221, 221, 221, 222, 224, 225, 225, 225, 226, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                          mask_data\n",
       "106      1  [75, 85, 82, 85, 83, 85, 84, 86, 79, 82, 86, 8...\n",
       "96       1  [111, 106, 107, 107, 110, 110, 105, 106, 103, ...\n",
       "18       1  [118, 132, 140, 152, 157, 165, 170, 172, 176, ...\n",
       "257      0  [170, 187, 169, 128, 127, 124, 123, 136, 137, ...\n",
       "126      1  [17, 16, 19, 15, 16, 19, 21, 18, 24, 25, 28, 3...\n",
       "..     ...                                                ...\n",
       "109      1  [194, 194, 195, 196, 196, 196, 198, 197, 196, ...\n",
       "127      1  [196, 205, 183, 186, 184, 139, 208, 205, 195, ...\n",
       "254      0  [189, 194, 200, 198, 196, 195, 190, 174, 170, ...\n",
       "259      0  [85, 52, 34, 30, 33, 32, 34, 69, 56, 68, 90, 7...\n",
       "177      0  [221, 221, 221, 222, 224, 225, 225, 225, 226, ...\n",
       "\n",
       "[302 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.DataFrame({'label': y_val_mask,'mask_data': val_mask})\n",
    "df_val = df_val.append(pd.DataFrame({'label': y_val_no_mask, 'mask_data': val_no_mask}), ignore_index=True)\n",
    "\n",
    "df_val = df_val.sample(frac = 1)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.iloc[:, 1:] / 255.0\n",
    "X_val = pd.DataFrame(X_val['mask_data'].tolist())\n",
    "y_val = df_val.iloc[:,:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/4ybwj4pj54x1sz2qhfgy1b9m0000gn/T/ipykernel_35193/4284791088.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test = df_test.append(pd.DataFrame({'label': y_test_no_mask, 'mask_data': test_no_mask}), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mask_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>[90, 90, 6, 8, 78, 118, 101, 103, 83, 21, 1, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>[62, 63, 62, 62, 62, 61, 62, 62, 62, 62, 61, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>[208, 198, 208, 209, 223, 222, 216, 212, 196, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>[236, 236, 236, 236, 236, 236, 236, 236, 236, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>[219, 219, 219, 219, 219, 218, 218, 217, 218, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>[229, 230, 230, 230, 231, 231, 229, 227, 224, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>[196, 196, 196, 197, 197, 197, 197, 193, 192, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>[140, 144, 143, 94, 59, 68, 60, 41, 86, 52, 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>[179, 190, 187, 180, 188, 182, 186, 181, 185, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>[222, 222, 222, 222, 222, 222, 222, 222, 222, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                          mask_data\n",
       "95      0  [90, 90, 6, 8, 78, 118, 101, 103, 83, 21, 1, 0...\n",
       "61      0  [62, 63, 62, 62, 62, 61, 62, 62, 62, 62, 61, 6...\n",
       "60      0  [208, 198, 208, 209, 223, 222, 216, 212, 196, ...\n",
       "48      1  [236, 236, 236, 236, 236, 236, 236, 236, 236, ...\n",
       "90      0  [219, 219, 219, 219, 219, 218, 218, 217, 218, ...\n",
       "..    ...                                                ...\n",
       "36      1  [229, 230, 230, 230, 231, 231, 229, 227, 224, ...\n",
       "39      1  [196, 196, 196, 197, 197, 197, 197, 193, 192, ...\n",
       "58      0  [140, 144, 143, 94, 59, 68, 60, 41, 86, 52, 58...\n",
       "77      0  [179, 190, 187, 180, 188, 182, 186, 181, 185, ...\n",
       "65      0  [222, 222, 222, 222, 222, 222, 222, 222, 222, ...\n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame({'label': y_test_mask,'mask_data': test_mask})\n",
    "df_test = df_test.append(pd.DataFrame({'label': y_test_no_mask, 'mask_data': test_no_mask}), ignore_index=True)\n",
    "\n",
    "df_test = df_test.sample(frac = 1)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[:, 1:] / 255.0\n",
    "X_test = pd.DataFrame(X_test['mask_data'].tolist())\n",
    "y_test = df_test.iloc[:, :1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.values.reshape(-1,100,100)\n",
    "x_val = X_val.values.reshape(-1,100,100)\n",
    "x_test = X_test.values.reshape(-1,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "# input image dimensions\n",
    "input_shape = (100, 100, 1)\n",
    "\n",
    "y = y_train #use later for the classifiers\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599, 100, 100)\n",
      "(302, 100, 100)\n",
      "(99, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K_Nearest_Neighbor Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 58 candidates, totalling 290 fits\n",
      "Best Parameters: {'n_neighbors': 22, 'weights': 'distance'}\n",
      "Accuracy Score: 0.7312605042016808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = list(range(1, 30))\n",
    "param_grid = {'n_neighbors': k_range, \n",
    "              'weights': ['uniform', 'distance']}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, verbose = 1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# lin_classifier = SGDClassifier()\n",
    "# lin_classifier.fit(X_train, y)\n",
    "# y_pred = lin_classifier.predict(X_test)\n",
    "\n",
    "# accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# # Train and evaluate several classifiers\n",
    "# classifiers = [\n",
    "#     LogisticRegression(),\n",
    "#     SVC(),\n",
    "# ]\n",
    "# y= y['label']\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train, y)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     print(type(clf).__name__)\n",
    "#     print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "#     print(\"Precision: {:.2f}\".format(precision_score(y_test, y_pred, average='weighted')))\n",
    "#     print(\"Recall: {:.2f}\".format(recall_score(y_test, y_pred, average='weighted')))\n",
    "#     print(\"F1-score: {:.2f}\".format(f1_score(y_test, y_pred, average='weighted')))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (Convolutional neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 49, 49, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 33856)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 33856)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33857     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,673\n",
      "Trainable params: 52,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The parameters I chose here were also from a project I did earlier, I'll link it here\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      6\u001b[0m              EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)]\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/21/4ybwj4pj54x1sz2qhfgy1b9m0000gn/T/__autograph_generated_filey7yvew9h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/haseebkhan/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=7)]\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('./best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/dev/schoolClasses/CISC-4900/lib/python3.8/site-packages/keras/engine/training.py:3160\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3155\u001b[0m   \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3156\u001b[0m   \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3157\u001b[0m   \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   3158\u001b[0m   \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3161\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3162\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3415547311306\n",
      "Test accuracy: 0.8585858345031738\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_labels, y_pred_labels))\n",
    "print(confusion_matrix(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import tkinter as tk\n",
    "# from PIL import Image, ImageTk\n",
    "\n",
    "# class CameraApp:\n",
    "#     def __init__(self, master):\n",
    "#         self.master = master\n",
    "#         master.title(\"Camera App\")\n",
    "\n",
    "#         # Create a button to take a picture\n",
    "#         self.button = tk.Button(master, text=\"Take Picture\", command=self.take_picture)\n",
    "#         self.button.pack()\n",
    "\n",
    "#         # Create a canvas to display the captured image\n",
    "#         self.canvas = tk.Canvas(master, width=640, height=480)\n",
    "#         self.canvas.pack()\n",
    "\n",
    "#     def take_picture(self):\n",
    "#         # Open the default camera\n",
    "#         cap = cv2.VideoCapture(0)\n",
    "\n",
    "#         # Capture a frame from the camera\n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         # Save the captured frame as an image\n",
    "#         self.image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "#         # Release the camera\n",
    "#         cap.release()\n",
    "\n",
    "#         # Display the captured image on the canvas\n",
    "#         self.photo = ImageTk.PhotoImage(self.image)\n",
    "#         self.canvas.create_image(0, 0, image=self.photo, anchor=tk.NW)\n",
    "\n",
    "# root = tk.Tk()\n",
    "# app = CameraApp(root)\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# cam = cv2.VideoCapture(0)\n",
    "\n",
    "# cv2.namedWindow(\"test\")\n",
    "\n",
    "# img_counter = 0\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cam.read()\n",
    "#     if not ret:\n",
    "#         print(\"failed to grab frame\")\n",
    "#         break\n",
    "#     cv2.imshow(\"test\", frame)\n",
    "\n",
    "#     k = cv2.waitKey(1)\n",
    "#     if k%256 == 27:\n",
    "#         # ESC pressed\n",
    "#         print(\"Escape hit, closing...\")\n",
    "#         break\n",
    "#     elif k%256 == 32:\n",
    "#         # SPACE pressed\n",
    "#         img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "#         cv2.imwrite(img_name, frame)\n",
    "#         print(\"{} written!\".format(img_name))\n",
    "#         img_counter += 1\n",
    "\n",
    "# cam.release()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    return \"<p>Hello, World!</p>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('opencv_frame_0.png'))\n",
    "grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "resized = cv2.resize(grayscale, input_shape)\n",
    "resized = np.reshape(resized, input_shape[0] * input_shape[1])\n",
    "\n",
    "\n",
    "# prediction = model.predict(image)\n",
    "resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 100)\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "[[0.17905957 0.82273626]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@jinilcs/a-simple-keras-model-on-my-laptop-webcam-dda77521e6a0\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "\n",
    "#Load the saved model\n",
    "model = models.load_model('best_model.h5')\n",
    "# video = cv2.VideoCapture(0)\n",
    "input_shape = (100,100)\n",
    "filename = 'opencv_frame_1.png'\n",
    "\n",
    "while True:\n",
    "    _, frame = video.read()\n",
    "\n",
    "    # frame = cv2.imread(filename)\n",
    "    #Convert the captured frame into RGB\n",
    "    im = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(im, input_shape)\n",
    "    resized = np.reshape(resized, input_shape[0] * input_shape[1])\n",
    "    im_df = pd.DataFrame(resized)\n",
    "    #Resizing into 100x100 because we trained the model with this image size.\n",
    "    X = im_df / 255.0\n",
    "    X = X.values.reshape(-1,100,100)\n",
    "    #Calling the predict method on model to predict 'me' on the image\n",
    "    print(model.predict(X))\n",
    "    prediction = int(model.predict(X)[0][0])\n",
    "\n",
    "    print(prediction)\n",
    "#     if prediction is 0, which means I am missing on the image, then show the frame in gray color.\n",
    "    if prediction == 0:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow(\"Capturing\", frame)\n",
    "    key=cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "            break\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 100)\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "[[0.0608748  0.94396263]]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@jinilcs/a-simple-keras-model-on-my-laptop-webcam-dda77521e6a0\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "# Define a function to make predictions\n",
    "def predict_mask(image):\n",
    "\n",
    "    frame = cv2.imread(image)\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, input_shape)\n",
    "\n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Resize the image to the correct dimensions (if necessary)\n",
    "    image_array = np.resize(image_array, (1, 100, 100))\n",
    "    \n",
    "    # Normalize the image data\n",
    "    image_array = image_array / 255.0\n",
    "    print(image_array.shape)\n",
    "    \n",
    "    # Make a prediction with the model\n",
    "    prediction = model.predict(image_array)\n",
    "    print(prediction)\n",
    "    \n",
    "    # Return the prediction\n",
    "    return prediction[0][0] > 0.5  # Returns True if wearing mask, False if not\n",
    "\n",
    "# Example usage\n",
    "# image = 'New_Masks_Dataset/Test/Mask/2085.jpg'\n",
    "# image = 'New_Masks_Dataset/Test/Non_Mask/real_01032.jpg'\n",
    "# image = 'New_Masks_Dataset/Test/Mask/2114.jpeg'\n",
    "# image = 'New_Masks_Dataset/Test/Non_Mask/real_01042.jpg'\n",
    "image = 'opencv_frame_0.png'\n",
    "\n",
    "prediction = predict_mask(image)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c13209e22e8d7786781c444ec5dd3ab2bdb4894b22799155f2d9a5b3d32d4296"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
